---
---


@inproceedings{LWHSZBCFZ22,
abbr={arXiv},
conferenceurlll={https://www.usenix.org/conference/usenixsecurity22},
author = {Yugeng Liu* and Rui Wen* and Xinlei He and Ahmed Salem and Zhikun Zhang and Michael Backes and Emiliano De Cristofaro and Mario Fritz and Yang Zhang},
title = {{ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models}},
booktitle = {{CoRR abs/2102.02551}},
bbbooktitle = {{USENIX Security Symposium}},
year = {2021},
lllocation = {Boston, MA, USA},
mmmonth={{Aug}},
url={https://arxiv.org/abs/2102.02551},
additional={* equal contribution},
pdf={mldoctor.pdf},
code = {https://github.com/liuyugeng/ML-Doctor},
abstract = {{Abstract:<br>Inference attacks against Machine Learning (ML) models allow adversaries to learn information about training data, model parameters, and so on. While researchers have studied several kinds of attacks thoroughly, they have done so in isolation. As a result, we lack a comprehensive picture of the risks caused by the attacks, e.g., the different scenarios they can be applied to, the common factors that influence their performance, the relationship among them, or the effectiveness of defense techniques. In this paper, we fill this gap by presenting a first-of-its-kind holistic risk assessment of different inference attacks against machine learning models. We concentrate on four attacks – membership inference, model inversion, attribute inference, and model stealing – and establish a threat model taxonomy.<br>Our extensive experimental evaluation, conducted over five model architectures and four image datasets, shows that the complexity of the training dataset plays an important role with respect to the attack’s performance, while the effectiveness of model stealing and membership inference attacks are negatively correlated. We also show that defenses like DP-SGD and Knowledge Distillation can only mitigate some of the inference attacks. Our analysis relies on a modular re-usable software, ML-DOCTOR, which enables ML model owners to assess the risks of deploying their models, and equally serves as a benchmark tool for researchers and practitioners.}}
}

@article{TXMYLHZL19,
abbr={COSE&apos;19},
author = {Zhushou Tang and Minhui Xue and Guozhu Meng and Chengguo Ying and Yugeng Liu and Jianan He and Haojin Zhu and Yang Liu},
title = {{Securing android applications via edge assistant third-party library detection}},
journal = {{Computers \& Security}},
year = {2019},
url={https://www.sciencedirect.com/science/article/pii/S0167404818311301},
pdf={cos19.pdf},
abstract = {{Abstract:<br>Third-party library (TPL) detection in Android has been a hot topic to security researchers for a long time. A precise yet scalable detection of TPLs in applications can greatly facilitate other security activities such as TPL integrity checking, malware detection, and privacy leakage detection. Since TPLs of specific versions may exhibit their own security issues, the identification of TPL as well as its concrete version, can help assess the security of Android APPs. However in reality, existing approaches of TPL detection suffer from low efficiency for their detection algorithm to impracticable and low accuracy due to insufficient analysis data, inappropriate features, or the disturbance from code obfuscation, shrinkage, and optimization.<br>In this paper, we present an automated approach, named PanGuard, to detect TPLs from an enormous number of Android APPs. We propose a novel combination of features including both structural and content information for packages in APPs to characterize TPLs. In order to address the difficulties caused by code obfuscation, shrinkage, and optimization, we identify the invariants that are unchanged during mutation, separate TPLs from the primary code in APPs, and use these invariants to determine the contained TPLs as well as their versions. The extensive experiments show that PanGuard achieves a high accuracy and scalability simultaneously in TPL detection. In order to accommodate to optimized TPL detection, which has not been mentioned by previous work, we adopt set analysis, which speed up the detection as a side effect.<br>PanGuard is implemented and applied on an industrial edge computing platform, and powers the identification of TPL. Beside fast detection algorithm, the edge computing deployment architecture make the detection scalable to real-time detection on a large volume of emerging APPs. Based on the detection results from millions of Android APPs, we successfully identify over 800 TPLs with 12 versions on average. By investigating the differences amongst these versions, we identify over 10 security issues in TPLs, and shed light on the significance of TPL detection with the caused harmful impacts on the Android ecosystem.}}
}

@inproceedings{ZMLZZZ18,
abbr={CCS&apos;18},
conferenceurl={https://www.sigsac.org/ccs/CCS2018/index.html},
author = {Wei Zhang and Yan Meng and Yugeng Liu and Xiaokuan Zhang and Yinqian Zhang and Haojin Zhu},
title = {{HoMonit: Monitoring Smart Home Apps from Encrypted Traffic}},
booktitle = {{ACM Conference on Computer and Communications Security}},
pages = {1074--1088},
publisher = {ACM},
location = {Toronto, Canada},
month = {{Oct}},
year = {2018},
url = {https://dl.acm.org/citation.cfm?id=3243820},
pdf = {ccs18.pdf},
ppt = {ccs18.pptx},
video = {https://youtu.be/i7LdzxmrH3w},
code = {ccs18homonit-groovy-codes.zip},
use = {{The 60 malicious apps}},
abstract = {{Abstract:<br>Smart home is an emerging technology for intelligently connecting a large variety of smart sensors and devices to facilitate automation of home appliances, lighting, heating and cooling systems, and security and safety systems. Our research revolves around Samsung SmartThings, a smart home platform with the largest number of apps among currently available smart home platforms. The previous research has revealed several security flaws in the design of SmartThings, which allow malicious smart home apps (or SmartApps) to possess more privileges than they were designed and to eavesdrop or spoof events in the SmartThings platform. To address these problems, this paper leverages side-channel inference capabilities to design and develop a system, dubbed HoMonit, to monitor SmartApps from encrypted wireless traffic. To detect anomaly, HoMonit compares the SmartApps activities inferred from the encrypted traffic with their expected behaviors dictated in their source code or UI interfaces. To evaluate the effectiveness of HoMonit, we analyzed 181 official SmartApps and performed evaluation on 60 malicious SmartApps, which either performed overprivileged accesses to smart devices or conducted event-spoofing attacks. The evaluation results suggest that HoMonit can effectively validate the working logic of SmartApps and achieve a high accuracy in the detection of SmartApp misbehaviors.}}
}
